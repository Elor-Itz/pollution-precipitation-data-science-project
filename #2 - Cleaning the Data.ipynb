{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139161f1",
   "metadata": {},
   "source": [
    "#2 - Cleaning the Data\n",
    "==================\n",
    "\n",
    "In order to prepare my final data file, the individual frames had to be cleaned and concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7336b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ca8cc",
   "metadata": {},
   "source": [
    "`Cleaning pollution data:`\n",
    "-------------------------------------\n",
    "\n",
    "In order to clean the data, I used several steps:\n",
    "\n",
    "**1.** I dropped the first column, and removed the '24:00' part of my date strings.\n",
    "\n",
    "**2.** I converted the data type of the three particle columns (**NO**, **NO2**, **NOX**) to float, using **coerce** to convert non-numeric values to NaN.\n",
    "\n",
    "**3.** I dealt with missing values by using the following strategy:\n",
    "\n",
    "* If the first two cells are **NaN**, their value will be **equal to the column's mean**. \n",
    "\n",
    "\n",
    "* If the last cell is **NaN**, it will be **equal to the column's current mean**.\n",
    "\n",
    "\n",
    "* For any other cell:\n",
    "\n",
    "    * If the next cell is **NaN**, the value will be **equal to the mean of the two previous cells**.\n",
    "    \n",
    "    * Otherwise, the value will be **equal to the mean of the previous and the next cells**.\n",
    "    \n",
    "The new file will be saved as **'pollution_data_cleaned.csv'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01a7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pollution_data(filename):\n",
    "    return pd.read_csv(filename)  #load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7729de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pollution_data(df, filename):\n",
    "    #Remove the generated index column\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)   \n",
    "        \n",
    "    #Remove 24:00 from the day strings\n",
    "    df['date'] = df['date'].str.replace(\"24:00 \", '')\n",
    "    \n",
    "    #Convert particle columns to numeric values\n",
    "    df['NO'] = pd.to_numeric(df['NO'], errors='coerce')\n",
    "    df['NO2'] = pd.to_numeric(df['NO2'], errors='coerce')\n",
    "    df['NOX'] = pd.to_numeric(df['NOX'], errors='coerce')    \n",
    "    \n",
    "    #Fill missing values according to the formula explained above\n",
    "    for column in df[['NO', 'NO2', 'NOX']]:        \n",
    "        for i in range(len(df[column])):            \n",
    "            curr = df.at[i, column]\n",
    "            #If first or second cell\n",
    "            if i == 0 or i == 1:                \n",
    "                #Ensure first values are not none, else fill them with the column's mean                \n",
    "                if pd.isnull(curr):\n",
    "                    df.at[i, column] = df[column].mean()\n",
    "                prev_2 = df.at[0, column]\n",
    "                prev = df.at[1, column]\n",
    "            #If last cell\n",
    "            if i == len(df[column]):\n",
    "                if pd.isnull(curr):\n",
    "                    df.at[i, column] = df[column].mean()            \n",
    "            #In the case of other cells\n",
    "            else:                \n",
    "                if pd.isnull(curr):\n",
    "                    #Check if the next value is NaN\n",
    "                    next = df.at[i+1, column]\n",
    "                    if pd.isnull(next):                        \n",
    "                        #If so, the value will be equal to the mean of the previous two values\n",
    "                        df.at[i, column] = ((prev_2 + prev)/2)\n",
    "                    else:\n",
    "                        #If not, the value will be the mean of the previous and the next\n",
    "                        df.at[i, column] = ((prev + next)/2)\n",
    "                prev_2 = prev\n",
    "                prev = df.at[i, column] \n",
    "    \n",
    "    df.to_csv('{0}.csv'.format(filename))\n",
    "    print(\"Cleaned dataframe created successfully.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff42593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataframe created successfully.\n"
     ]
    }
   ],
   "source": [
    "poll_filename = 'pollution_data_raw.csv'\n",
    "poll_filename_new = 'pollution_data_cleaned'\n",
    "df_poll = load_pollution_data(poll_filename)\n",
    "df_poll_clean = clean_pollution_data(df_poll, poll_filename_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049c636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        object\n",
       "station     object\n",
       "NO         float64\n",
       "NO2        float64\n",
       "NOX        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poll_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8548b",
   "metadata": {},
   "source": [
    "**The cleaned pollution dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ede9d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>2.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23746</th>\n",
       "      <td>27/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>11.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>28/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>11.5</td>\n",
       "      <td>28.1</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>29/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>31.2</td>\n",
       "      <td>40.2</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>19.3</td>\n",
       "      <td>44.7</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>85.1</td>\n",
       "      <td>66.1</td>\n",
       "      <td>151.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23751 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date   station    NO   NO2    NOX\n",
       "0      01/01/2016     Ariel   1.5   3.8    6.1\n",
       "1      02/01/2016     Ariel   1.1   4.9    6.7\n",
       "2      03/01/2016     Ariel   1.4  10.8   13.0\n",
       "3      04/01/2016     Ariel   1.8   9.7   12.5\n",
       "4      05/01/2016     Ariel   2.1  11.8   15.1\n",
       "...           ...       ...   ...   ...    ...\n",
       "23746  27/12/2020  Tel Aviv  11.7  28.0   39.7\n",
       "23747  28/12/2020  Tel Aviv  11.5  28.1   39.6\n",
       "23748  29/12/2020  Tel Aviv  31.2  40.2   71.4\n",
       "23749  30/12/2020  Tel Aviv  19.3  44.7   64.1\n",
       "23750  31/12/2020  Tel Aviv  85.1  66.1  151.2\n",
       "\n",
       "[23751 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poll_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15acdc1",
   "metadata": {},
   "source": [
    "`Cleaning precipitation data:`\n",
    "-------------------------------------\n",
    "\n",
    "Here, I had different issues to deal with:\n",
    "\n",
    "**1.** Since the text was in Hebrew, I had to encode the data in the ISO-8859-8 format, which supports the Hebrew alphabet.\n",
    "\n",
    "**2.** I dropped the irrelevant columns - such as the station number.\n",
    "\n",
    "**3.** I translated the column names to English, and then converted the station names from Hebrew to the exact English names used in the df_poll dataframe by using a dictionary and mapping the values after cleaning auto-generated white spaces in the Hebrew strings.\n",
    "\n",
    "The new file will be saved as **'precipitation_data_cleaned.csv'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a855bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_precipitation_data(filename):\n",
    "    return pd.read_csv(filename, encoding = \"ISO-8859-8\")  #load file with Hebrew encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e9d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_precipitation_data(df, filename):\n",
    "    #Drop irrelevant columns\n",
    "    df.drop(['מספר תחנה', 'קוד גשם יומי()'], axis=1, inplace = True)\n",
    "\n",
    "    #Change column names\n",
    "    df.rename(columns={'שם תחנה': \"station\", 'תאריך': \"date\", 'כמות גשם יומית(מ\"מ)': \"precipitation\"}, inplace = True)\n",
    "\n",
    "    #Translate station names\n",
    "    stations = {\"אריאל מכללה\": 'Ariel',\n",
    "                \"אשדוד נמל\": 'Ashdod',\n",
    "                \"באר שבע\": 'Beer Sheva',\n",
    "                \"חדרה תחנת הכח\": 'Hadera',\n",
    "                \"חיפה בתי זיקוק\": 'Haifa',\n",
    "                \"ירושלים מרכז\": 'Jerusalem',\n",
    "                \"כפר מנחם, כפר מנחם\": 'Kfar Menachem',\n",
    "                \"אשחר\": 'Karmiel',\n",
    "                \"עפולה ניר העמק\": 'Afula',\n",
    "                \"ערד\": 'Arad',\n",
    "                \"גת\": 'Kiryat Gat',\n",
    "                \"ראשון לציון\": 'Rishon LeZion',\n",
    "                \"תל-אביב חוף\": 'Tel Aviv'}\n",
    "\n",
    "    df['station'] = df['station'].str.strip()\n",
    "    df['station'] = df['station'].map(stations)\n",
    "    \n",
    "    df['precipitation'] = pd.to_numeric(df['precipitation'], errors='coerce')\n",
    "    \n",
    "    df.to_csv('{0}.csv'.format(filename))\n",
    "    print(\"Cleaned dataframe created successfully.\")    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffca7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataframe created successfully.\n"
     ]
    }
   ],
   "source": [
    "prec_filename = 'precipitation_data_raw.csv'\n",
    "prec_filename_new = 'precipitation_data_cleaned'\n",
    "df_prec = load_precipitation_data(prec_filename)\n",
    "df_prec_clean = clean_precipitation_data(df_prec, prec_filename_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74294d4a",
   "metadata": {},
   "source": [
    "**The cleaned precipitation dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf03bc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afula</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afula</td>\n",
       "      <td>02/01/2016</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afula</td>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afula</td>\n",
       "      <td>07/01/2016</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afula</td>\n",
       "      <td>08/01/2016</td>\n",
       "      <td>39.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>15/12/2020</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>16/12/2020</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>17/12/2020</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>23/12/2020</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>24/12/2020</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3734 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station        date  precipitation\n",
       "0        Afula  01/01/2016           10.3\n",
       "1        Afula  02/01/2016            8.3\n",
       "2        Afula  03/01/2016            0.9\n",
       "3        Afula  07/01/2016           29.5\n",
       "4        Afula  08/01/2016           39.9\n",
       "...        ...         ...            ...\n",
       "3729  Tel Aviv  15/12/2020           19.9\n",
       "3730  Tel Aviv  16/12/2020           58.2\n",
       "3731  Tel Aviv  17/12/2020            8.5\n",
       "3732  Tel Aviv  23/12/2020            5.3\n",
       "3733  Tel Aviv  24/12/2020            0.9\n",
       "\n",
       "[3734 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prec_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3623494",
   "metadata": {},
   "source": [
    "`Concatenating the data:`\n",
    "-------------------------------------\n",
    "\n",
    "In order to concatenate the data, I had to use the **df.merge** function, fitting the relevant precipitation data in **df_prec** into the correct locations in the in the **df_poll** dataframe based on the date and station. Since precipitation data is only given in 3734 records, I assumed that the other days had no recorded precipitation, and filled them with 0s.\n",
    "\n",
    "The new, and final file will be saved as **'data_final.csv'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa69ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data(df_poll, df_prec, filename):\n",
    "    merged_df = df_poll.merge(df_prec, how = 'left', on = ['date', 'station'])\n",
    "    merged_df['precipitation'] = merged_df['precipitation'].fillna(0)\n",
    "    \n",
    "    merged_df.to_csv('{0}.csv'.format(filename))\n",
    "    print(\"Concatenated dataframe created successfully.\")    \n",
    "    return merged_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbcb4268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated dataframe created successfully.\n"
     ]
    }
   ],
   "source": [
    "filename_final = 'data_final'\n",
    "df_final = concat_data(df_poll, df_prec, filename_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf37520",
   "metadata": {},
   "source": [
    "**The final dataframe, which will be used in the next steps:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7158d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/01/2016</td>\n",
       "      <td>Ariel</td>\n",
       "      <td>2.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23746</th>\n",
       "      <td>27/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>11.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>28/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>11.5</td>\n",
       "      <td>28.1</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>29/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>31.2</td>\n",
       "      <td>40.2</td>\n",
       "      <td>71.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>19.3</td>\n",
       "      <td>44.7</td>\n",
       "      <td>64.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>31/12/2020</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>85.1</td>\n",
       "      <td>66.1</td>\n",
       "      <td>151.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23751 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date   station    NO   NO2    NOX  precipitation\n",
       "0      01/01/2016     Ariel   1.5   3.8    6.1           13.6\n",
       "1      02/01/2016     Ariel   1.1   4.9    6.7            7.4\n",
       "2      03/01/2016     Ariel   1.4  10.8   13.0            9.0\n",
       "3      04/01/2016     Ariel   1.8   9.7   12.5            0.0\n",
       "4      05/01/2016     Ariel   2.1  11.8   15.1            0.0\n",
       "...           ...       ...   ...   ...    ...            ...\n",
       "23746  27/12/2020  Tel Aviv  11.7  28.0   39.7            0.0\n",
       "23747  28/12/2020  Tel Aviv  11.5  28.1   39.6            0.0\n",
       "23748  29/12/2020  Tel Aviv  31.2  40.2   71.4            0.0\n",
       "23749  30/12/2020  Tel Aviv  19.3  44.7   64.1            0.0\n",
       "23750  31/12/2020  Tel Aviv  85.1  66.1  151.2            0.0\n",
       "\n",
       "[23751 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79799f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
